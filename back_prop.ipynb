{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Performing backpropagation of the neural network manually**"
      ],
      "metadata": {
        "id": "p7_k8C0UOIHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mQqYu1snBo0O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "vH4nsL8BB4DI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "len(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpsKQ6-7CCPO",
        "outputId": "daf83122-e983-4a09-b54f-c370301dffae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(itos)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaYcWQ36CDcz",
        "outputId": "2cbb0156-901c-46f6-fd88-076c1f15634f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3 # context length: how many characters do we take to predict the next one\n",
        "\n",
        "def build_dataset(words):\n",
        "  # build the dataset\n",
        "\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      #print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "92TcRsjbCJJZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = build_dataset(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7bv9APoJEcK",
        "outputId": "7442b514-78ee-438d-cadb-ac9d659c1fb6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([228146, 3]) torch.Size([228146])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xval, Yval = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiY4ji6CCNhE",
        "outputId": "b806dd38-b2f5-4dd7-8d22-5598666250bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  max = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approx: {str(app):5s} | max: {max :.4f}')"
      ],
      "metadata": {
        "id": "qpl514ZjC80K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_emb = 10\n",
        "n_hidden = 64\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((vocab_size, n_emb), generator=g)\n",
        "\n",
        "# Weights and bias\n",
        "W1 = torch.randn((n_emb * block_size, n_hidden), generator=g) * (5/3) / (n_emb * block_size) ** 0.5\n",
        "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
        "\n",
        "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1            # Non-zero\n",
        "b2 = torch.randn(vocab_size, generator=g) * 0.1                        # Since (+)\n",
        "\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "\n",
        "#batch_mean_running = torch.zeros((1, n_hidden))\n",
        "#batch_std_running = torch.ones((1, n_hidden))\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for params in parameters:\n",
        "  params.requires_grad = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzFV4dIwC0N6",
        "outputId": "bbfb1ea6-320a-48c3-9213-27a44cb6bcb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n = batch_size\n",
        "\n",
        "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator = g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]"
      ],
      "metadata": {
        "id": "fkCxfngsC5X1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "emb = C[Xb]\n",
        "embcat = emb.view(emb.shape[0], -1)\n",
        "\n",
        "# linear layer 1\n",
        "hprebn = embcat @ W1 + b1\n",
        "\n",
        "# batch norm\n",
        "bnmeani = 1 / n * hprebn.sum(0, keepdim = True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff ** 2\n",
        "\n",
        "bnvar = 1 / (n -1) * (bndiff2).sum(0,keepdim = True)\n",
        "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# non-linearity\n",
        "h = torch.tanh(hpreact)\n",
        "\n",
        "# linear layer 2\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# cross entropy loss\n",
        "logit_maxes = logits.max(dim = 1, keepdim = True).values\n",
        "norm_logits = logits - logit_maxes\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(dim = 1, keepdim = True)\n",
        "counts_sum_inv = counts_sum ** -1\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "print(loss)\n",
        "\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlzH2huSDgXJ",
        "outputId": "fbd713a3-6f8a-400d-a42b-ed5212a5b253"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.3371, grad_fn=<NegBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3371, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYw5-8qOEM9S",
        "outputId": "e641d492-43c8-45fc-c958-ea796759f674"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs[range(n), Yb]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svFDhpTnOh1k",
        "outputId": "dc1d8b7d-bcc4-415a-9c6f-5c55fb38a9c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-4.0311, -2.9819, -3.6523, -3.1949, -4.0918, -3.4804, -3.1895, -3.9604,\n",
              "        -3.1707, -4.3185, -3.0729, -1.6510, -2.8187, -2.8728, -3.0539, -3.2078,\n",
              "        -3.9542, -2.9665, -3.5485, -3.3537, -2.8585, -2.9726, -4.3352, -3.9869,\n",
              "        -3.4841, -2.9785, -2.9755, -3.9133, -2.7782, -3.4376, -3.2804, -3.2136],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loss = -logprobs[range(n), Yb].mean()**\n",
        "\n",
        "```\n",
        "dloss / dlogprobs\n",
        "=> d(-logprobs[range(n), Yb].mean()) / dlogprobs\n",
        "\n",
        "In short,\n",
        "loss = (a + b + .... + n) / N\n",
        "dloss / da = 1/N\n",
        ".\n",
        ".\n",
        ".\n",
        "dloss / dN = 1/N\n",
        "\n",
        "\n",
        "so, dloss / dlogprobs = -(1/n)\n",
        "```"
      ],
      "metadata": {
        "id": "3Fex28ssMywv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1. / n\n",
        "cmp('logprobs', dlogprobs, logprobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xvMxB_4L4pu",
        "outputId": "f174168b-784a-4731-b735-19bf2d09cdea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**logprobs = probs.log()**\n",
        "\n",
        "```\n",
        "dlogprobs / dprobs\n",
        "=> d(probs.log()) / dprobs\n",
        "=> 1 / probs\n",
        "\n",
        "dloss / dprobs\n",
        "=> der loss / der logprobs * der logprobs / der probs\n",
        "=> dlogprobs * der logprobs / der probs\n",
        "=> dlogprobs * (1 / probs)\n",
        "```"
      ],
      "metadata": {
        "id": "wS5x7dmlPjAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs = torch.zeros_like(probs)\n",
        "dprobs = dlogprobs * (1/probs)\n",
        "cmp('probs', dprobs, probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaDKu3I1RgNH",
        "outputId": "8bb6e7d0-5d0a-4c6c-c407-2e9736426c77"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs           | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**probs = counts * counts_sum_inv**\n",
        "\n",
        "```\n",
        "der probs / der counts_sum_inv\n",
        "=> der (counts * counts_sum_inv) / der counts_sum_inv\n",
        "=> counts\n",
        "\n",
        "der loss / der counts_sum_inv\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv\n",
        "=> dprobs * (der probs / der counts_sum_inv)\n",
        "=> dprobs * counts\n",
        "```\n",
        "\n",
        "```\n",
        "a(3 * 3) * b(3 * 1)\n",
        "\n",
        "(a11b1 a12b1 a13b1).sum()\n",
        "(a21b2 a22b2 a23b2).sum()\n",
        "(a31b3 a32b3 a33b3).sum()\n",
        "```"
      ],
      "metadata": {
        "id": "Yzc8qTAWTCbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(counts_sum_inv.shape,\n",
        " counts.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8PIK5BhUdKV",
        "outputId": "edd4082b-039b-48f7-9660-9311180dfc79"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1]), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum_inv = torch.zeros_like(counts_sum_inv)\n",
        "dcounts_sum_inv = (dprobs * counts).sum(1, keepdim = True)    # since diff size, summing up\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WreYGk6NUDez",
        "outputId": "f4c85254-fb58-474b-eb7d-9d6e91376bd4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts_sum_inv  | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**probs = counts * counts_sum_inv**\n",
        "\n",
        "```\n",
        "der probs / der counts\n",
        "=> der(counts * counts_sum_inv) / der counts\n",
        "=> counts_sum_inv\n",
        "\n",
        "dloss / dcounts\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts\n",
        "=> dprobs * der probs / der counts\n",
        "=> dprobs * counts_sum_inv\n",
        "```"
      ],
      "metadata": {
        "id": "myPTzt67XJz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(probs.shape,\n",
        " counts_sum_inv.shape,\n",
        " counts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkzAI1FEX3pX",
        "outputId": "e1631679-a277-4996-9649-590b3f6bedfe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 1]), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts = torch.zeros_like(counts)\n",
        "dcounts = dprobs * counts_sum_inv\n",
        "\n",
        "# there is another branch for dcounts and some grad needs to be added"
      ],
      "metadata": {
        "id": "GZUnNGI4WcCS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**counts_sum_inv = counts_sum ^ -1**\n",
        "\n",
        "```\n",
        "der counts_sum_inv / der counts_sum\n",
        "=> der (counts_sum ^ -1) / der counts_sum\n",
        "=> (-1) * counts_sum ^ (-1-1)\n",
        "=> (-1) * counts_sum ^ (-2)\n",
        "=> -1 * counts_sum ** -2\n",
        "\n",
        "dloss / dcounts_sum\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum\n",
        "=> dcounts_sum_inv * (der counts_sum_inv / der counts_sum)\n",
        "=> dcounts_sum_inv * (-1 * counts_sum ** -2)\n",
        "```"
      ],
      "metadata": {
        "id": "-XkIcDyOZDlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(counts_sum.shape,\n",
        " counts_sum_inv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58olc8bnasjA",
        "outputId": "9b85dc2c-bf9a-4877-e863-254843dc8edd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum = torch.zeros_like(counts_sum)\n",
        "dcounts_sum = dcounts_sum_inv * (-1 * counts_sum ** -2)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP9iJLAXagXO",
        "outputId": "cc38d34c-8e0b-4589-d53e-2ebd3f6047b8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts_sum      | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**counts_sum = counts.sum(dim = 1, keepdim = True)**\n",
        "\n",
        "```\n",
        "der counts_sum / der counts\n",
        "=> 1(counts.shape)\n",
        "\n",
        "dloss / dcounts\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts\n",
        "=> dcount_sum * der counts_sum / der counts\n",
        "=> dcount_sum * 1(counts.shape)\n",
        "```\n",
        "\n",
        "```\n",
        "[a+b+c\n",
        " d+e+f\n",
        " g+h+i]\n",
        "\n",
        "[a b c\n",
        " d e f\n",
        " g h i]\n",
        "\n",
        "\n",
        "[der a+b+c/der a  der a+b+c/der b  der a+b+c/der c\n",
        " der d+e+f/der d  der d+e+f/der e  der d+e+f/der f\n",
        " der g+h+i/der g  der g+h+i/der h  der g+h+i/der i]   \n",
        "```\n"
      ],
      "metadata": {
        "id": "CeHBDsRTazzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{counts.shape} = {counts_sum.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwUGbRW1bJNz",
        "outputId": "522c3a06-513e-4b82-b7f4-50b071542597"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 27]) = torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts += (dcounts_sum * torch.ones_like(counts))\n",
        "cmp('counts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv8CZLY9dVVG",
        "outputId": "d3c415b4-cfd5-4b76-f3ea-22e6fc588d6b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts          | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**counts = norm_logits.exp()**\n",
        "\n",
        "```\n",
        "der counts / der norm_logits\n",
        "=> der(norm_logits.exp()) / der norm_logits\n",
        "=> norm_logits.exp()\n",
        "\n",
        "dloss / dnorm_logits\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits\n",
        "=> dcounts * der counts / der norm_logits\n",
        "=> dcounts * norm_logits.exp()\n",
        "```\n"
      ],
      "metadata": {
        "id": "nf3CFCLOfpoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(counts.shape,\n",
        " norm_logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZiU0AVFfY3k",
        "outputId": "082caeea-a54b-430c-fa33-2c09a93e9d05"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dnorm_logits = torch.zeros_like(norm_logits)\n",
        "dnorm_logits = dcounts * norm_logits.exp()\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVH4aDbmgX8x",
        "outputId": "eac402e7-614b-4d85-d759-eb1a2463b0d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm_logits     | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**norm_logits = logits - logit_maxes**\n",
        "\n",
        "```\n",
        "der norm_logits / der logits\n",
        "=> der(logits - logit_maxes) / der logits\n",
        "=> 1.0\n",
        "\n",
        "dloss / dlogits\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits\n",
        "=> dnorm_logits * der norm_logits / der logits\n",
        "=> dnorm_logits * 1.0\n",
        "```\n",
        "\n",
        "```\n",
        "der norm_logits / der logits_maxes\n",
        "=> der(logits - logit_maxes) / der logits\n",
        "=> - 1.0(shape of logit_maxes)\n",
        "\n",
        "dloss / dlogits_maxes\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits\n",
        "=> dnorm_logits * der norm_logits / der logits_maxes\n",
        "=> dnorm_logits * -1.0(shape of logit_maxes)\n",
        "```"
      ],
      "metadata": {
        "id": "zzzA2dvSgi1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{logits.shape} => {norm_logits.shape} * ({logits.shape} - {logit_maxes.shape})')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8yH2ZPuhACn",
        "outputId": "207021b5-6347-4007-be81-663ef4e180ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 27]) => torch.Size([32, 27]) * (torch.Size([32, 27]) - torch.Size([32, 1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits_maxes = torch.zeros_like(logit_maxes)\n",
        "dlogits_maxes = (dnorm_logits * -1.0).sum(1, keepdim = True)\n",
        "cmp('logits_maxes', dlogits_maxes, logit_maxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij8KlR4OjDFv",
        "outputId": "450ecf88-f561-4066-bf02-eb8fd75a6b23"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_maxes    | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits = torch.zeros_like(logits)\n",
        "dlogits = dnorm_logits * torch.ones(32,27)\n",
        "\n",
        "# there is another branch for logits"
      ],
      "metadata": {
        "id": "UHolKYcuhG9D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**logit_maxes = logits.max(dim = 1, keepdim = True).values**\n",
        "\n",
        "```\n",
        "der logits_maxes / der logits\n",
        "=> 1.0(if it is max num else 0)\n",
        "=> sum of the row will be 1 for each row\n",
        "\n",
        "\n",
        "dloss / dlogits\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits\n",
        "=> dlogits_maxes * der logits_maxes / der logits\n",
        "=> dlogits_maxes * 1.0(across each row)\n",
        "```"
      ],
      "metadata": {
        "id": "J4B9yfiYjVU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(logit_maxes.shape,\n",
        " logits.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-SVGVQ4kAJv",
        "outputId": "8113e3ac-9a75-469c-89a5-8642fdc6660a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1]), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits += F.one_hot(torch.argmax(logits, dim = 1), num_classes = vocab_size) * dlogits_maxes\n",
        "cmp('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3-fHLQlraNB",
        "outputId": "5987990d-0f0f-4734-99ae-f32a3d853dc0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits          | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**logits = h @ W2 + b2**\n",
        "\n",
        "```\n",
        "der logits / der h\n",
        "=> der(h @ W2 + b2)\n",
        "=> W2\n",
        "\n",
        "dloss / dh\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h\n",
        "=> dlogits * der logits / der h\n",
        "=> dlogits * W2\n",
        "```"
      ],
      "metadata": {
        "id": "KMdMgM90r7Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape, W2.shape, dlogits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_tJ0EfftWDS",
        "outputId": "8314d577-c6a0-4afe-b601-d8c58cbbe6f6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([64, 27]), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh = torch.ones_like(h)\n",
        "dh = dlogits @ W2.T\n",
        "cmp('h', dh, h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgSpUxM5r3yV",
        "outputId": "5f5315df-a7be-4174-b6d3-dea4cd8c0dc7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h               | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**logits = h @ W2 + b2**\n",
        "\n",
        "```\n",
        "der logits / der W2\n",
        "=> der(h @ W2 + b2)\n",
        "=> h\n",
        "\n",
        "dloss / dW2\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der W2\n",
        "=> dlogits * der logits / der W2\n",
        "=> dlogits * h\n",
        "```"
      ],
      "metadata": {
        "id": "0yB8yPXowcyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dW2 = torch.ones_like(W2)\n",
        "dW2 = h.T @ dlogits\n",
        "cmp('W2', dW2, W2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTanp-fpwjLO",
        "outputId": "6a7b4d5c-a216-49a1-9525-8997e599c480"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2              | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**logits = h @ W2 + b2**\n",
        "\n",
        "```\n",
        "der logits / der b2\n",
        "=> der(h @ W2 + b2)\n",
        "=> 1\n",
        "\n",
        "dloss / db2\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der b2\n",
        "=> dlogits * der logits / der b2\n",
        "=> dlogits * 1.0\n",
        "```"
      ],
      "metadata": {
        "id": "c2gSPgkzxqpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b2.shape, logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVctRJ7yx6uj",
        "outputId": "42bc5f53-2664-4bc2-9dd5-2ecfd4956a79"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([27]), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db2 = torch.ones_like(b2)\n",
        "db2 = (dlogits * 1.0).sum(0, keepdim = True)\n",
        "cmp('b2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVq6on-Nwzco",
        "outputId": "cfe73978-8f70-401a-9ac0-e63250de0823"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b2              | exact: True  | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**h = torch.tanh(hpreact)**\n",
        "\n",
        "```\n",
        "der h * der hpreact\n",
        "=> der(tanh(hpreact)) / der h\n",
        "=> 1 - tan**2(hpreact)\n",
        "=> 1 - h**2\n",
        "\n",
        "dloss / hpreact2\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / hpreact\n",
        "=> dh * der h / der hpreact\n",
        "=> dh * (1 - (h**2))\n",
        "```"
      ],
      "metadata": {
        "id": "my42zWGvynSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape, hpreact.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRuZRMtzyg2u",
        "outputId": "cc391164-a803-4bd7-e106-148b7877a0ca"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhpreact = torch.ones_like(hpreact)\n",
        "dhpreact = (1 - h**2) * dh\n",
        "cmp('hpreact', dhpreact, hpreact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Sp0L76z9rn",
        "outputId": "44136396-1056-4040-f119-ac1e91542031"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hpreact         | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hpreact = bngain * bnraw + bnbias**\n",
        "\n",
        "```\n",
        "der hpreact / der bngain\n",
        "=> der (bngain * bnraw + bnbias) / der bngain\n",
        "=> bnraw\n",
        "\n",
        "dloss / hpreact2\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bngain\n",
        "=> dhpreact * der hpreact / der bngain\n",
        "=> dhpreact * bnraw\n",
        "```"
      ],
      "metadata": {
        "id": "9RNDrCbW1bRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hpreact.shape, bnraw.shape, bngain.shape, bnbias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKvFLTZh2ZoF",
        "outputId": "b4e3f458-d687-4f51-ce5d-1ef39c055f68"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([1, 64]),\n",
              " torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbngain = torch.ones_like(bngain)\n",
        "dbngain = (dhpreact * bnraw).sum(0, keepdim = True)\n",
        "cmp('bngain', dbngain, bngain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJefdQqs1aQL",
        "outputId": "346e5d3f-c7f8-44b5-a011-3e03d3e1eab3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bngain          | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hpreact = bngain * bnraw + bnbias**\n",
        "\n",
        "```\n",
        "der hpreact / der bnraw\n",
        "=> der (bngain * bnraw + bnbias) / der bnraw\n",
        "=> bngain\n",
        "\n",
        "dloss / hpreact2\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw\n",
        "=> dhpreact * der hpreact / der bnraw\n",
        "=> dhpreact * bngain\n",
        "```"
      ],
      "metadata": {
        "id": "KEJ2xDYb_Sb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbnraw = torch.ones_like(bnraw)\n",
        "dbnraw = (dhpreact * bngain)\n",
        "cmp('bnraw', dbnraw, bnraw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uMIvz8j_R6b",
        "outputId": "97e4bd7f-55b4-46f4-9902-1f381f1cb13e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnraw           | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hpreact = bngain * bnraw + bnbias**\n",
        "\n",
        "```\n",
        "der hpreact / der bnbias\n",
        "=> der (bngain * bnraw + bnbias) / der bnbias\n",
        "=> 1.0\n",
        "\n",
        "dloss / hpreact2\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnbias\n",
        "=> dhpreact * der hpreact / der bnbias\n",
        "=> dhpreact * 1.0\n",
        "```"
      ],
      "metadata": {
        "id": "OQeFqN_UAFwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbnbias = torch.ones_like(bnraw)\n",
        "dbnbias = (dhpreact * 1.0).sum(0, keepdim = True)\n",
        "cmp('bnbias', dbnbias, bnbias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeMV8GTCAFEt",
        "outputId": "9d3a8ced-bdca-45c4-adc7-b5b6a82c690b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnbias          | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bnraw = bndiff * bnvar_inv**\n",
        "\n",
        "```\n",
        "der bnraw / der bndiff\n",
        "=> der (bndiff * bnvar_inv) / der bndiff\n",
        "=> bnvar_inv\n",
        "\n",
        "dloss / bnvar_inv\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bndiff\n",
        "=> dbnraw * der bnraw / der bndiff\n",
        "=> dbnraw * bnvar_inv\n",
        "```\n",
        "\n",
        "```\n",
        "der bnraw / der bnvar_inv\n",
        "=> der (bndiff * bnvar_inv) / der bnvar_inv\n",
        "=> bndiff\n",
        "\n",
        "dloss / bnvar_inv\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv\n",
        "=> dbnraw * der bnraw / der bnvar_inv\n",
        "=> dbnraw * bndiff\n",
        "```"
      ],
      "metadata": {
        "id": "6oBRPjwsS0D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bndiff.shape, bnvar_inv.shape, dbnraw.shape"
      ],
      "metadata": {
        "id": "3xKVtSGPAnoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf99a38f-458c-460c-81c0-d3b6ad4f674f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([1, 64]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbnvar_inv = torch.ones_like(bnvar_inv)\n",
        "dbnvar_inv = (dbnraw * bndiff).sum(0, keepdim = True)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grxJpYflU34J",
        "outputId": "5b1f3c5a-e4be-449c-890e-094adef79d7d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnvar_inv       | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff = torch.ones_like(bndiff)\n",
        "dbndiff = dbnraw * bnvar_inv\n",
        "\n",
        "# there is another branch for dbndiff"
      ],
      "metadata": {
        "id": "A6KcuCGxTY6W"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bnvar_inv = (bnvar + 1e-5) ^ -0.5**\n",
        "\n",
        "```\n",
        "der bnvar_inv / der bnvar\n",
        "=> der((bnvar + 1e-5) ^ -0.5) / der bnvar\n",
        "=> -0.5 * (bnvar + 1e-5) ** -1.5 * 1\n",
        "=> -0.5 * (bnvar + 1e-5) ** -1.5\n",
        "\n",
        "dloss / bnvar_inv\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar\n",
        "=> dbnvar_inv * der bnvar_inv / der bnvar\n",
        "=> dbnvar_inv * -0.5 * ((bnvar + 1e-5) ** -1.5)\n",
        "```"
      ],
      "metadata": {
        "id": "eDBsR5HgVPS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnvar_inv.shape, bnvar.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9xOOnjaXIMr",
        "outputId": "8425788f-827e-437e-b60a-db1ecabd23ca"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbnvar = torch.ones_like(bnvar)\n",
        "dbnvar = dbnvar_inv * -0.5 * ((bnvar + 1e-5) ** -1.5)\n",
        "cmp('bnvar', dbnvar, bnvar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOLJv6nHXM_t",
        "outputId": "c31b5fd5-1745-4469-e10f-ebc0da20f349"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnvar           | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bnvar = 1 / (n -1) * (bndiff2).sum(0,keepdim = True)**\n",
        "\n",
        "```\n",
        "der bnvar / der bndiff2\n",
        "=> der (1 / (n -1) * (bndiff2).sum()) / der bndiff\n",
        "=> (1 / (n-1) )\n",
        "\n",
        "dloss / bndiff2\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2\n",
        "=> dbnvar * der bnvar / der bndiff2\n",
        "=> dbnvar * (1 / (n - 1 ) )\n",
        "```"
      ],
      "metadata": {
        "id": "dEbiTennXmPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnvar.shape, bndiff2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-btomLr6XeiE",
        "outputId": "c0cccf11-116e-4f52-8516-f00933a66768"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 64]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff2 = torch.ones_like(bndiff2)\n",
        "dbndiff2 = dbnvar * (1 / (n - 1) * dbndiff2)\n",
        "cmp('bndiff2', dbndiff2, bndiff2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AbsK-RaaG4O",
        "outputId": "8b0cca35-cd6f-467e-b70e-dcd840d3bc03"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bndiff2         | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bndiff2 = bndiff ^ 2**\n",
        "\n",
        "```\n",
        "der bndiff2 / der bndiff\n",
        "=> der (bndiff ** 2) / der bndiff\n",
        "=> 2 * (bndiff)\n",
        "\n",
        "dloss / bndiff\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / bndiff\n",
        "=> dbndiff2 * der bndiff2 / der bndiff\n",
        "=> dbndiff2 * 2 * bndiff\n",
        "```"
      ],
      "metadata": {
        "id": "B9Wd-nWMciET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff2.shape, dbndiff.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtphrWa1dAeQ",
        "outputId": "e4bac956-dbb5-4c95-f354-dcc2df4a10eb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff += (2 * bndiff) * dbndiff2\n",
        "cmp('bndiff', dbndiff, bndiff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X6FngQgdDh2",
        "outputId": "c3a3e5ff-2955-45f4-a650-633abfe7be7d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bndiff          | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bndiff = hprebn - bnmeani**\n",
        "\n",
        "```\n",
        "der bndiff / der hprebn\n",
        "=> der (hprebn - bnmeani) / der hprebn\n",
        "=> 1.0\n",
        "\n",
        "dloss / hprebn\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn\n",
        "=> dbndiff * der bndiff / der hprebn\n",
        "=> dbndiff * 1.0\n",
        "```\n",
        "\n",
        "```\n",
        "der bndiff / der bnmeani\n",
        "=> der (hprebn - bnmeani) / der bnmeani\n",
        "=> -1 (sum along 0th dim)\n",
        "\n",
        "dloss / bnmeani\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn\n",
        "=> dbndiff * der bndiff / der hprebn\n",
        "=> dbndiff * -1 (sum along 0th dim)\n",
        "```"
      ],
      "metadata": {
        "id": "MNtH86cQee1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hprebn.shape, bnmeani.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URxiw-4yeeBG",
        "outputId": "4e95d68e-85cd-4205-fe7d-a0998cd7a5e4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbnmeani = torch.ones_like(bnmeani)\n",
        "dbnmeani = (dbndiff * -1).sum(0, keepdim = True)\n",
        "cmp('bnmeani', dbnmeani, bnmeani)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdcxE8IIgLKJ",
        "outputId": "c63df8f4-9fbd-4efd-a8ee-b6455100feef"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnmeani         | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn = torch.ones_like(hprebn)\n",
        "dhprebn = dbndiff * 1.0\n",
        "\n",
        "# there is another branch of hprebn"
      ],
      "metadata": {
        "id": "-fwETbHWfNJv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bnmeani = 1 / n * hprebn.sum(0, keepdim = True)**\n",
        "\n",
        "```\n",
        "der bnmeani / der hprebn\n",
        "=> der (1 / n * hprebn.sum()) / der hprebn\n",
        "=> 1 / n\n",
        "\n",
        "dloss / hprebn\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn * der bndiff / der bnmeani * der bnmeani / der hprebn\n",
        "=> dbnmeani * der bnmeani / der hprebn\n",
        "=> dbnmeani * 1 / n\n",
        "```"
      ],
      "metadata": {
        "id": "9X5jCbXkiRxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn += 1.0 /n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "cmp('hprebn', dhprebn, hprebn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1G15X3siRL8",
        "outputId": "ccf090c6-11e6-4be6-ad5c-20b7b563c26b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hprebn          | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hprebn = embcat @ W1 + b1**\n",
        "\n",
        "```\n",
        "der hprebn / der embcat\n",
        "=> der (embcat @ W1 + b1) / der embcat\n",
        "=> W1\n",
        "\n",
        "dloss / embcat\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn * der bndiff / der bnmeani * der meani / der hprebn * der hprebn / der embcat\n",
        "=> dhprebn * der hprebn / der embcat\n",
        "=> dhprebn * W1\n",
        "```\n",
        "\n",
        "```\n",
        "der hprebn / der W1\n",
        "=> der (embcat @ W1 + b1) / der W1\n",
        "=> embcat\n",
        "\n",
        "dloss / W1\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn * der bndiff / der bnmeani * der meani / der hprebn * der hprebn / der W1\n",
        "=> dhprebn * der hprebn / der W1\n",
        "=> dhprebn * embcat\n",
        "```\n",
        "\n",
        "```\n",
        "der hprebn / der b1\n",
        "=> der (embcat @ W1 + b1) / der b1\n",
        "=> 1.0\n",
        "\n",
        "dloss / b1\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn * der bndiff / der bnmeani * der meani / der hprebn * der hprebn / der b1\n",
        "=> dhprebn * der hprebn / der b1\n",
        "=> dhprebn * 1.0\n",
        "```"
      ],
      "metadata": {
        "id": "Bp_kNbjqx-Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{embcat.shape} => {dhprebn.shape} * {W1.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHqp9K4TwHPd",
        "outputId": "9453f0f1-6abc-4f4b-d809-d3661efc046b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 30]) => torch.Size([32, 64]) * torch.Size([30, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dembcat = torch.ones_like(embcat)\n",
        "dembcat = dhprebn @ W1.T\n",
        "cmp('embcat', dembcat, embcat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP8KCzt-zgK7",
        "outputId": "018b2787-62d3-422f-ed8e-53ffc791896b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embcat          | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{W1.shape} => {dhprebn.shape} * {embcat.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xO8i05K0bV2",
        "outputId": "3f49e75d-d9ab-4ea6-c59a-258bc02b9213"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 64]) => torch.Size([32, 64]) * torch.Size([32, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW1 = torch.ones_like(W1)\n",
        "dW1 = embcat.T @ dhprebn\n",
        "cmp('W1', dW1, W1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBXfB5UM0AsV",
        "outputId": "ae5822e9-8e57-41a7-951f-b1d74bbc6a6f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1              | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn.shape, b1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNSciJiX0pUO",
        "outputId": "b4107b7a-5d49-4bd5-db1d-796b30e3bd56"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db1 = torch.ones_like(b1)\n",
        "db1 = (dhprebn * 1.0).sum(0, keepdim = True)\n",
        "cmp('b1', db1, b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHZ4lJR90hJS",
        "outputId": "37a49d38-8897-4063-f43f-ebb3ce76f021"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b1              | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**embcat = emb.view(emb.shape[0], -1)**\n",
        "\n",
        "```\n",
        "der embcat / der emb\n",
        "=> der (emb.view(emb.shape[0], -1)) / der emb\n",
        "=> 1.0\n",
        "\n",
        "dloss / emb\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn * der bndiff / der bnmeani * der meani / der hprebn * der hprebn / der embcat * der embcat / der emb\n",
        "=> dembcat * der embcat / der emb\n",
        "=> dembcat * 1.0(with change in shape)\n",
        "```"
      ],
      "metadata": {
        "id": "dUfvV4Tn1e4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embcat.shape, emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zap5b7P108a-",
        "outputId": "74527b6e-fdd3-43f5-aed1-bdc9f8cbca56"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demb = torch.ones_like(emb)\n",
        "demb = (dembcat * 1.0).view(emb.shape)\n",
        "cmp('emb', demb, emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nttdCReO5AbY",
        "outputId": "e024dc32-0487-41d1-a312-cf45242471b6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb             | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**emb = C[Xb]**\n",
        "\n",
        "```\n",
        "der emb / der C\n",
        "=> der (C[Xb]) / der C\n",
        "=> 1\n",
        "\n",
        "dloss / C\n",
        "=> der loss / der logprobs * der logprobs / der probs * der probs / der counts_sum_inv * der counts_sum_inv / der counts_sum * der counts_sum / der counts * der counts / der norm_logits * der norm_logits / der logits_maxes * der logits_maxes / der logits * der logits / der h * der h / der hpreact * der hpreact / der bnraw * der bnraw / der bnvar_inv * der bnvar_inv / der bnvar * der bnvar / der bndiff2 * der bndiff2 / der bndiff * der bndiff / der hprebn * der bndiff / der bnmeani * der meani / der hprebn * der hprebn / der embcat * der embcat / der emb * der emb / der C\n",
        "=> demb * der emb / der C\n",
        "=> demb * 1\n",
        "```"
      ],
      "metadata": {
        "id": "wwtpWgtu5RuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape, C.shape, Xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ttprOeB50_a",
        "outputId": "ee6065a4-5216-4cc2-bb02-c505a1f45b59"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dC = torch.zeros_like(C)\n",
        "for i in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    dC[Xb[i, j]] += (demb[i,j] * 1.0)\n",
        "cmp('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUy5-hhw6D7m",
        "outputId": "29c40f59-a674-4245-c333-738e0a33ae6a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C               | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dC.shape, C.shape,\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osFI4pib6uyx",
        "outputId": "fe031ee2-a232-403f-fbf2-a9e078a6e955"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([27, 10]), torch.Size([27, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **In Summary**"
      ],
      "metadata": {
        "id": "Bcoh0j2x7RnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "emb = C[Xb]\n",
        "embcat = emb.view(emb.shape[0], -1)\n",
        "\n",
        "# linear layer 1\n",
        "hprebn = embcat @ W1 + b1\n",
        "\n",
        "# batch norm\n",
        "bnmeani = 1 / n * hprebn.sum(0, keepdim = True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff ** 2\n",
        "\n",
        "bnvar = 1 / (n -1) * (bndiff2).sum(0,keepdim = True)\n",
        "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# non-linearity\n",
        "h = torch.tanh(hpreact)\n",
        "\n",
        "# linear layer 2\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# cross entropy loss\n",
        "logit_maxes = logits.max(1, keepdim = True).values\n",
        "norm_logits = logits - logit_maxes\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdim = True)\n",
        "counts_sum_inv = counts_sum ** -1\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "print(loss)\n",
        "\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fy-7j1p-KwD",
        "outputId": "0910c47f-e451-46c8-a682-ea7e6597a2cf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.3371, grad_fn=<NegBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3371, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1. / n\n",
        "\n",
        "dprobs = torch.zeros_like(probs)\n",
        "dprobs = dlogprobs * (1/probs)\n",
        "\n",
        "dcounts_sum_inv = torch.zeros_like(counts_sum_inv)\n",
        "dcounts_sum_inv = (dprobs * counts).sum(1, keepdim = True)    # since diff size, summing up\n",
        "\n",
        "dcounts = torch.zeros_like(counts)\n",
        "dcounts = dprobs * counts_sum_inv\n",
        "\n",
        "dcounts_sum = torch.zeros_like(counts_sum)\n",
        "dcounts_sum = dcounts_sum_inv * (-1 * counts_sum ** -2)\n",
        "\n",
        "dcounts += (dcounts_sum * torch.ones_like(counts))\n",
        "\n",
        "dnorm_logits = torch.zeros_like(norm_logits)\n",
        "dnorm_logits = dcounts * norm_logits.exp()\n",
        "\n",
        "dlogits_maxes = torch.zeros_like(logit_maxes)\n",
        "dlogits_maxes = (dnorm_logits * -1.0).sum(1, keepdim = True)\n",
        "\n",
        "dlogits = torch.zeros_like(logits)\n",
        "dlogits = dnorm_logits * torch.ones(32,27)\n",
        "\n",
        "dlogits += F.one_hot(torch.argmax(logits, dim = 1), num_classes = vocab_size) * dlogits_maxes\n",
        "\n",
        "dh = torch.ones_like(h)\n",
        "dh = dlogits @ W2.T\n",
        "\n",
        "dW2 = torch.ones_like(W2)\n",
        "dW2 = h.T @ dlogits\n",
        "\n",
        "db2 = torch.ones_like(b2)\n",
        "db2 = (dlogits * 1.0).sum(0, keepdim = True)\n",
        "\n",
        "dhpreact = torch.ones_like(hpreact)\n",
        "dhpreact = (1 - h**2) * dh\n",
        "\n",
        "dbngain = torch.ones_like(bngain)\n",
        "dbngain = (dhpreact * bnraw).sum(0, keepdim = True)\n",
        "\n",
        "dbnraw = torch.ones_like(bnraw)\n",
        "dbnraw = (dhpreact * bngain)\n",
        "\n",
        "dbnbias = torch.ones_like(bnraw)\n",
        "dbnbias = (dhpreact * 1.0).sum(0, keepdim = True)\n",
        "\n",
        "dbnvar_inv = torch.ones_like(bnvar_inv)\n",
        "dbnvar_inv = (dbnraw * bndiff).sum(0, keepdim = True)\n",
        "\n",
        "dbndiff = torch.ones_like(bndiff)\n",
        "dbndiff = dbnraw * bnvar_inv\n",
        "\n",
        "dbnvar = torch.ones_like(bnvar)\n",
        "dbnvar = dbnvar_inv * -0.5 * ((bnvar + 1e-5) ** -1.5)\n",
        "\n",
        "dbndiff2 = torch.ones_like(bndiff2)\n",
        "dbndiff2 = dbnvar * (1 / (n - 1) * dbndiff2)\n",
        "\n",
        "dbndiff += (2 * bndiff) * dbndiff2\n",
        "\n",
        "dbnmeani = torch.ones_like(bnmeani)\n",
        "dbnmeani = (dbndiff * -1).sum(0, keepdim = True)\n",
        "\n",
        "dhprebn = torch.ones_like(hprebn)\n",
        "dhprebn = dbndiff * 1.0\n",
        "\n",
        "dhprebn += 1.0 /n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "dembcat = torch.ones_like(embcat)\n",
        "dembcat = dhprebn @ W1.T\n",
        "\n",
        "dW1 = torch.ones_like(W1)\n",
        "dW1 = embcat.T @ dhprebn\n",
        "\n",
        "db1 = torch.ones_like(b1)\n",
        "db1 = (dhprebn * 1.0).sum(0, keepdim = True)\n",
        "\n",
        "demb = torch.ones_like(emb)\n",
        "demb = (dembcat * 1.0).view(emb.shape)\n",
        "\n",
        "dC = torch.zeros_like(C)\n",
        "for i in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    dC[Xb[i, j]] += (demb[i,j] * 1.0)\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "cmp('logits_maxes', dlogits_maxes, logit_maxes)\n",
        "cmp('logits', dlogits, logits)\n",
        "cmp('h', dh, h)\n",
        "cmp('W2', dW2, W2)\n",
        "cmp('b2', db2, b2)\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "cmp('bngain', dbngain, bngain)\n",
        "cmp('bnraw', dbnraw, bnraw)\n",
        "cmp('bnbias', dbnbias, bnbias)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "cmp('bnvar', dbnvar, bnvar)\n",
        "cmp('bndiff2', dbndiff2, bndiff2)\n",
        "cmp('bndiff', dbndiff, bndiff)\n",
        "cmp('bnmeani', dbnmeani, bnmeani)\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "cmp('embcat', dembcat, embcat)\n",
        "cmp('W1', dW1, W1)\n",
        "cmp('b1', db1, b1)\n",
        "cmp('emb', demb, emb)\n",
        "cmp('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vObu6JN97fKm",
        "outputId": "a6dfbf0a-0f56-4e9b-bc3c-2ce304343a8b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approx: True  | max: 0.0000\n",
            "probs           | exact: True  | approx: True  | max: 0.0000\n",
            "counts_sum_inv  | exact: True  | approx: True  | max: 0.0000\n",
            "counts_sum      | exact: True  | approx: True  | max: 0.0000\n",
            "counts          | exact: True  | approx: True  | max: 0.0000\n",
            "norm_logits     | exact: True  | approx: True  | max: 0.0000\n",
            "logits_maxes    | exact: True  | approx: True  | max: 0.0000\n",
            "logits          | exact: True  | approx: True  | max: 0.0000\n",
            "h               | exact: True  | approx: True  | max: 0.0000\n",
            "W2              | exact: True  | approx: True  | max: 0.0000\n",
            "b2              | exact: True  | approx: True  | max: 0.0000\n",
            "hpreact         | exact: False | approx: True  | max: 0.0000\n",
            "bngain          | exact: False | approx: True  | max: 0.0000\n",
            "bnraw           | exact: False | approx: True  | max: 0.0000\n",
            "bnbias          | exact: False | approx: True  | max: 0.0000\n",
            "bnvar_inv       | exact: False | approx: True  | max: 0.0000\n",
            "bnvar           | exact: False | approx: True  | max: 0.0000\n",
            "bndiff2         | exact: False | approx: True  | max: 0.0000\n",
            "bndiff          | exact: False | approx: True  | max: 0.0000\n",
            "bnmeani         | exact: False | approx: True  | max: 0.0000\n",
            "hprebn          | exact: False | approx: True  | max: 0.0000\n",
            "embcat          | exact: False | approx: True  | max: 0.0000\n",
            "W1              | exact: False | approx: True  | max: 0.0000\n",
            "b1              | exact: False | approx: True  | max: 0.0000\n",
            "emb             | exact: False | approx: True  | max: 0.0000\n",
            "C               | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "g6m_sPstcbZO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Back-prop for the cross-entropy**\n",
        "\n",
        "```\n",
        "logit_maxes = logits.max(1, keepdim = True).values\n",
        "norm_logits = logits - logit_maxes\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdim = True)\n",
        "counts_sum_inv = counts_sum ** -1\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "V1lz-_hIEiZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits = F.softmax(logits, 1)\n",
        "dlogits[range(n), Yb] -= 1\n",
        "dlogits /= n\n",
        "\n",
        "cmp('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjJWYMoEXNdU",
        "outputId": "e4da33ba-a9de-46d4-e2ac-0c6a17716ac8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits          | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "plt.imshow(dlogits.detach(), cmap = 'gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "QDLcIA5rbiz1",
        "outputId": "6e2139e6-fa6a-46ec-e4f1-7cea2c6efef2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7eac2d4cde40>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Back-prop for the batch-norm**\n",
        "\n",
        "```\n",
        "bnmeani = 1 / n * hprebn.sum(0, keepdim = True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff ** 2\n",
        "\n",
        "bnvar = 1 / (n -1) * (bndiff2).sum(0,keepdim = True)\n",
        "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "```"
      ],
      "metadata": {
        "id": "wKE7kDnabFR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hpreact.shape, bnraw.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEFuii2Hnk4M",
        "outputId": "1415d1bb-8c5d-4853-d12f-24cca3e47fb1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn = bngain * bnvar_inv / n * (n * dhpreact - dhpreact.sum(0) - n / (n-1) * bnraw * (dhpreact * bnraw).sum(0))\n",
        "cmp('hpreact', dhpreact, hpreact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrX8vV1Z2doZ",
        "outputId": "1e7e42a7-80b8-4dab-e3f9-46c98a977ecf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hpreact         | exact: False | approx: True  | max: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Back-prop final implementation**"
      ],
      "metadata": {
        "id": "awGfXGFj5IIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass ---------------\n",
        "emb = C[Xb]\n",
        "embcat = emb.view(emb.shape[0], -1)\n",
        "\n",
        "# linear layer 1\n",
        "hprebn = embcat @ W1 + b1\n",
        "\n",
        "# batch norm\n",
        "bnmeani = 1 / n * hprebn.sum(0, keepdim = True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff ** 2\n",
        "\n",
        "bnvar = 1 / (n -1) * (bndiff2).sum(0,keepdim = True)\n",
        "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# non-linearity\n",
        "h = torch.tanh(hpreact)\n",
        "\n",
        "# linear layer 2\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# cross entropy loss\n",
        "logit_maxes = logits.max(1, keepdim = True).values\n",
        "norm_logits = logits - logit_maxes\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdim = True)\n",
        "counts_sum_inv = counts_sum ** -1\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "print(loss)\n",
        "\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "# -------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oK6_jPm5Fau",
        "outputId": "f52c7be8-9867-4fe0-e884-9b570595fdc9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.3371, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backprop -----------\n",
        "# output layer\n",
        "dlogits = F.softmax(logits, 1)\n",
        "dlogits[range(n), Yb] -= 1\n",
        "dlogits /= n\n",
        "\n",
        "# 2nd layer\n",
        "dh = dlogits @ W2.T\n",
        "dW2 = h.T @ dlogits\n",
        "db2 = (dlogits * 1.0).sum(0)\n",
        "\n",
        "# tanh\n",
        "dhpreact = (1 - h**2) * dh\n",
        "\n",
        "# back-norm\n",
        "dbnbias = (dhpreact * 1.0).sum(0, keepdim = True)\n",
        "dbngain = (dhpreact * bnraw).sum(0, keepdim = True)\n",
        "dhprebn = bngain * bnvar_inv / n * (n * dhpreact - dhpreact.sum(0) - n / (n-1) * bnraw * (dhpreact * bnraw).sum(0))\n",
        "\n",
        "# firstlayer\n",
        "dembcat = dhprebn @ W1.T\n",
        "dW1 = embcat.T @ dhprebn\n",
        "db1 = (dhprebn * 1.0).sum(0)\n",
        "\n",
        "# embedding\n",
        "demb = (dembcat * 1.0).view(emb.shape)\n",
        "dC = torch.zeros_like(C)\n",
        "for i in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    dC[Xb[i, j]] += (demb[i,j] * 1.0)\n",
        "\n",
        "grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "# -------------------"
      ],
      "metadata": {
        "id": "uQFQveTj53Ja"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upgrade -----------\n",
        "lr = 0.1\n",
        "for p, grad in zip(parameters, grads):\n",
        "  p.data += -lr * grad\n",
        "# -------------------"
      ],
      "metadata": {
        "id": "XLmMXElG8GvQ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Entire linear model witb manual back-propagation**"
      ],
      "metadata": {
        "id": "KfGxTNU_89rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_emb = 10\n",
        "n_hidden = 64\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((vocab_size, n_emb), generator=g)\n",
        "\n",
        "# Weights and bias\n",
        "W1 = torch.randn((n_emb * block_size, n_hidden), generator=g) * (5/3) / (n_emb * block_size) ** 0.5\n",
        "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
        "\n",
        "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1            # Non-zero\n",
        "b2 = torch.randn(vocab_size, generator=g) * 0.1                        # Since (+)\n",
        "\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "\n",
        "#batch_mean_running = torch.zeros((1, n_hidden))\n",
        "#batch_std_running = torch.ones((1, n_hidden))\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters))\n",
        "\n",
        "for params in parameters:\n",
        "  params.requires_grad = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn6uUiLE9Prf",
        "outputId": "7f112508-d278-49f9-95ce-86446c28421b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.12\n",
        "epochs = 70000\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "losses = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for epoch in range(epochs + 1):\n",
        "    ix = torch.randint(0, X.shape[0], (batch_size,))\n",
        "    Xb, Yb = X[ix], Y[ix]\n",
        "\n",
        "    # forward pass ---------------\n",
        "    emb = C[Xb]\n",
        "    embcat = emb.view(emb.shape[0], -1)\n",
        "\n",
        "    # linear layer 1\n",
        "    hprebn = embcat @ W1 + b1\n",
        "\n",
        "    # batch norm\n",
        "    bnmean = hprebn.mean(0, keepdim = True)\n",
        "    bnvar = hprebn.var(0,keepdim = True, unbiased = True)\n",
        "    bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "    hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "    # non-linearity\n",
        "    h = torch.tanh(hpreact)\n",
        "\n",
        "    # linear layer 2\n",
        "    logits = h @ W2 + b2\n",
        "\n",
        "    # cross entropy loss\n",
        "    loss = F.cross_entropy(logits, Yb)\n",
        "    losses.append(loss.item())\n",
        "    if epoch % 10000 == 0:\n",
        "      print(f'{epoch} / {epochs} : loss => {loss.item() : .4f} {\"# \" * (epoch//10000)}')\n",
        "\n",
        "    for p in parameters:\n",
        "      p.grad = None\n",
        "\n",
        "    # -------------------\n",
        "\n",
        "    # backprop -----------\n",
        "    # output layer\n",
        "    dlogits = F.softmax(logits, 1)\n",
        "    dlogits[range(n), Yb] -= 1\n",
        "    dlogits /= n\n",
        "\n",
        "    # 2nd layer\n",
        "    dh = dlogits @ W2.T\n",
        "    dW2 = h.T @ dlogits\n",
        "    db2 = (dlogits * 1.0).sum(0)\n",
        "\n",
        "    # tanh\n",
        "    dhpreact = (1 - h**2) * dh\n",
        "\n",
        "    # back-norm\n",
        "    dbngain = (dhpreact * bnraw).sum(0, keepdim = True)\n",
        "    dbnbias = (dhpreact * 1.0).sum(0, keepdim = True)\n",
        "    dhprebn = bngain * bnvar_inv / n * (n * dhpreact - dhpreact.sum(0) - n / (n-1) * bnraw * (dhpreact * bnraw).sum(0))\n",
        "\n",
        "    # firstlayer\n",
        "    dembcat = dhprebn @ W1.T\n",
        "    dW1 = embcat.T @ dhprebn\n",
        "    db1 = (dhprebn * 1.0).sum(0)\n",
        "\n",
        "    # embedding\n",
        "    demb = (dembcat * 1.0).view(emb.shape)\n",
        "    dC = torch.zeros_like(C)\n",
        "    for i in range(Xb.shape[0]):\n",
        "      for j in range(Xb.shape[1]):\n",
        "        dC[Xb[i, j]] += (demb[i,j] * 1.0)\n",
        "\n",
        "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "    # -------------------\n",
        "\n",
        "    # upgrade -----------\n",
        "    lr = 0.1 if epoch < 50000 else 0.01\n",
        "    for p, grad in zip(parameters, grads):\n",
        "      p.data += -lr * grad\n",
        "    # -------------------\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ95yDYb8lGd",
        "outputId": "76be5016-7d69-4569-c191-71b99a778fb4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 70000 : loss =>  3.5286 \n",
            "10000 / 70000 : loss =>  2.4218 # \n",
            "20000 / 70000 : loss =>  2.2394 # # \n",
            "30000 / 70000 : loss =>  1.9767 # # # \n",
            "40000 / 70000 : loss =>  2.3623 # # # # \n",
            "50000 / 70000 : loss =>  2.2283 # # # # # \n",
            "60000 / 70000 : loss =>  2.1087 # # # # # # \n",
            "70000 / 70000 : loss =>  1.9477 # # # # # # # \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for evalution of the model\n",
        "# for p,g in zip(parameters, grads):\n",
        "#   cmp(str(tuple(p.shape)), g, p)"
      ],
      "metadata": {
        "id": "ik3f8oD2CPzv"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtr]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
      ],
      "metadata": {
        "id": "D40zlkPBNi-d"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(x, y):\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(f'loss : {loss.item() : .4f}')\n",
        "\n",
        "split_loss(X, Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssRE7GVPNoAk",
        "outputId": "cab00b3d-c5e9-4847-9245-197093391ad0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  2.1817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # ------------\n",
        "      # forward pass:\n",
        "      # Embedding\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "      hpreact = embcat @ W1 + b1\n",
        "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "      logits = h @ W2 + b2 # (N, vocab_size)\n",
        "      # ------------\n",
        "      # Sample\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMrp913JNqnQ",
        "outputId": "f9b99fc8-ef1b-4178-ed3e-e8d7f2ab4e9c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mria.\n",
            "gmyanniee.\n",
            "medhayla.\n",
            "rethruthadrie.\n",
            "caderedieliah.\n",
            "miloen.\n",
            "edellean.\n",
            "aarielleiorone.\n",
            "cayshubergihiriel.\n",
            "kindretlyn.\n",
            "joberlyn.\n",
            "brey.\n",
            "dariyah.\n",
            "fael.\n",
            "yuma.\n",
            "myston.\n",
            "azhil.\n",
            "salynn.\n",
            "ustullel.\n",
            "juren.\n"
          ]
        }
      ]
    }
  ]
}